# TTS-Datensatz-Formatter

Dieses Tool ist eine grafische Benutzeroberfl√§che (GUI) zur Verarbeitung von Audiodateien, um hochwertige Datens√§tze f√ºr das Training von Text-to-Speech (TTS)-Modellen zu erstellen. Die Pipeline ist darauf ausgelegt, Audiodateien intelligent zu segmentieren, zu filtern, zu bereinigen und zu transkribieren.

## Funktionen

- **Grafische Benutzeroberfl√§che**: Einfache Bedienung per Drag & Drop und Klick.
- **Gender-Filterung**: Automatische Erkennung und Filterung von m√§nnlichen und weiblichen Stimmen.
- **Intelligente Segmentierung**: Teilt Audiodateien basierend auf stillen Pausen und Prosodie-Analyse (Satzmelodie) in optimale L√§ngen (standardm√§√üig 2.5-12 Sekunden).
- **Professionelles Audio-Preprocessing**:
  - Rauschunterdr√ºckung (Spectral Gating)
  - Normalisierung (Peak & LUFS)
  - Hochpassfilter zur Entfernung von St√∂rger√§uschen
  - De-Essing zur Reduzierung von Zischlauten
  - Automatisches Trimmen von Stille am Anfang und Ende
- **Qualit√§tskontrolle**: Verwirft automatisch Segmente mit schlechter Qualit√§t (z.B. niedriges Signal-Rausch-Verh√§ltnis, Clipping).
- **Transkription**: Nutzt OpenAI Whisper (oder das schnellere `faster-whisper`), um die Audio-Segmente zu transkribieren.
- **Caching**: Speichert bereits get√§tigte Transkriptionen, um wiederholte Arbeit zu vermeiden.
- **Export**: Erstellt ein ZIP-Archiv mit den verarbeiteten `.wav`-Dateien und einer `metadata.tsv`-Datei, die f√ºr das TTS-Training bereit ist.
- **Gender-Kalibrierung**: Erm√∂glicht das Trainieren eines eigenen Modells zur Geschlechtererkennung f√ºr bessere Ergebnisse.

## Anforderungen

Das Skript ben√∂tigt die folgenden Python-Bibliotheken:

- `pydub`
- `librosa`
- `numpy`
- `openai-whisper`
- `PySimpleGUI`
- `num2words`
- `scikit-learn`
- `soundfile`
- `gTTS`
- `faster-whisper`
- `pytest` (f√ºr die Entwicklung)
- `pytest-mock` (f√ºr die Entwicklung)

## Installation

1.  Stellen Sie sicher, dass Sie Python 3.8 oder neuer installiert haben.
2.  Installieren Sie die erforderlichen Bibliotheken mit `pip`:
    ```bash
    pip install -r requirements.txt
    ```
3.  Stellen Sie au√üerdem sicher, dass `ffmpeg` auf Ihrem System installiert und im System-PATH verf√ºgbar ist. `pydub` ben√∂tigt es f√ºr die Audioverarbeitung.

## Verwendung

1.  Starten Sie das Skript √ºber die Kommandozeile:
    ```bash
    python main1.py
    ```
2.  **Dateien hinzuf√ºgen**: F√ºgen Sie Audiodateien (.wav, .mp3, etc.) oder ganze Ordner √ºber den "Hinzuf√ºgen"-Button oder per Drag & Drop hinzu.
3.  **Einstellungen w√§hlen**:
    - **Whisper Modell**: W√§hlen Sie die gew√ºnschte Modellgr√∂√üe (z.B. `small` f√ºr einen guten Kompromiss aus Geschwindigkeit und Genauigkeit).
    - **Engine**: `auto` w√§hlt automatisch die schnellste verf√ºgbare Whisper-Implementierung (`faster-whisper` wird bevorzugt).
    - **Gender-Filter**: W√§hlen Sie, ob Sie nur m√§nnliche, nur weibliche oder alle Stimmen verarbeiten m√∂chten.
4.  **Ressourcen laden**: Klicken Sie auf "Ressourcen laden", um das gew√§hlte Whisper-Modell in den Speicher zu laden. Der Start-Button wird danach aktiv.
5.  **Start**: Klicken Sie auf "Start", um die Verarbeitungspipeline zu beginnen.
6.  **Ergebnis**: Nach Abschluss des Prozesses finden Sie im `results`-Ordner ein ZIP-Archiv (`session_JJJJMMTT_HHMMSS.zip`), das Ihren fertigen Datensatz enth√§lt.

## Die Pipeline-Schritte im Detail

1.  **Gender-Filterung**: Wenn ein Filter (m√§nnlich/weiblich) aktiv ist, wird jede Datei analysiert und nur die passenden werden f√ºr die weiteren Schritte ausgew√§hlt.
2.  **Segmentierung**: Jede Audiodatei wird auf Basis von stillen Passagen und der Satzmelodie in kleinere Segmente zerlegt. Das Ziel ist es, einzelne S√§tze oder Teils√§tze zu isolieren.
3.  **Preprocessing**: Jedes einzelne Segment durchl√§uft eine Kette von Audio-Filtern, um die Qualit√§t zu maximieren. Segmente, die die Qualit√§tspr√ºfung nicht bestehen, werden verworfen.
4.  **Transkription**: Die hochwertigen Segmente werden mit Whisper transkribiert. Der Text wird normalisiert (Zahlen in W√∂rter umgewandelt, Satzzeichen entfernt).
5.  **Export**: Alle erfolgreich verarbeiteten Segmente werden als `.wav`-Dateien zusammen mit einer `metadata.tsv`-Datei in einem ZIP-Archiv gespeichert.

## Gender-Kalibrierung

Wenn die automatische Geschlechtererkennung f√ºr Ihr Audiomaterial nicht optimal funktioniert, k√∂nnen Sie ein eigenes Modell trainieren:

1.  Klicken Sie auf "üéôÔ∏è Gender-Kalibrierung".
2.  W√§hlen Sie einige Beispiel-Audiodateien aus, die eindeutig m√§nnliche oder weibliche Sprecher enthalten.
3.  Markieren Sie die entsprechenden Dateien in der Tabelle und weisen Sie ihnen √ºber die Buttons "Als M√§nnlich" / "Als Weiblich" das korrekte Geschlecht zu.
4.  Klicken Sie auf "Training starten". Sie ben√∂tigen mindestens 2 Beispiele f√ºr jedes Geschlecht.
5.  Das neu trainierte Modell wird automatisch f√ºr zuk√ºnftige Filterungen verwendet.
